{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Copy of assignment2_2021S.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "I3NY7sfLled4"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/levi3001/cs576_assigment/blob/main/assignment2_2021S.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTUYbQLlYUQ-"
      },
      "source": [
        "# CS576 Assignment #2: Image Classification using Convolutional Neural Networks (CNNs) \n",
        "---\n",
        "Primary TA : Whie Jung\n",
        "\n",
        "TA's E-mail : whieya@kaist.ac.kr, wogns98@kaist.ac.kr \n",
        "\n",
        "QnA Channel: Same Slack workspace but with *assignment2* channel (https://join.slack.com/t/kaistcs576/shared_invite/zt-o3gqak0y-yj3NCb_SQFxVkqO0U6PWYw)\n",
        "\n",
        "---\n",
        "\n",
        "## Instruction\n",
        "- In this assignment, we will classify the images in CIFAR10 dataset into 10 categories (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck) using Convolutional Neural Networks.  \n",
        "\n",
        "- For this, you first need to implement necessary network components (e.g. residual blocks) using nn.Module class. Then, you need to implement data pipeline. Finally, you need to implement an entire training/test pipeline.  \n",
        "\n",
        "- In each part, you will be given a starter code for the implementation. Please read the attached illustrations and instructions carefully to implement the codes.  \n",
        "\n",
        "- As you follow the given steps, fill in the section marked ***Px.x*** (e.g. P1.1, P1.2, etc) with the appropriate code.\n",
        "\n",
        "- DO NOT modify any of the skeleton codes except the area where we allow you to change. Please write your codes only in the designated area.\n",
        "\n",
        "## Submission guidelines\n",
        "- Your code and report will be all in Colab. \n",
        "- Go to the [link](https://drive.google.com/drive/folders/1XQT-Mk31_jc3KqXYX1FyMIcmtLutrKzj?usp=sharing), find `assignment2.ipynb` and `dataset.tar.gz`, save them into your own google drive by clicking `make a copy(사본만들기)`. Find the copies in your drive, change their name to `assignment2.ipynb` and `dataset.tar.gz`, respectively, if their names were changed to e.g. `Copy of assignment2.ipyb` or `assignment2.ipynb의 사본`. Also, keep them in a single directory.\n",
        "- <font color=\"red\"> You will get the full credit **only if** you complete the code **and** write a discussion of the results in the discussion section at the bottom of this page. </font>\n",
        "- We should be able to reproduce your results using your code. Please double-check if your code runs without error and reproduces your results. Submissions failed to run or reproduce the results will get a substantial penalty. \n",
        "\n",
        "## Deliverables\n",
        "- Download your Colab notebook and submit it in a format as : **[StudentID].ipynb**.\n",
        "- Your assignment should be submitted through KLMS. All other submissions (e.g., via email) will not be considered as valid submissions. \n",
        "\n",
        "## Due date\n",
        "- **23:59:59 May 4th.**\n",
        "- Late submission is allowed until 23:59:59 May 6th.\n",
        "- Late submission will be applied 20% penalty.\n",
        "\n",
        "\n",
        "## Questions\n",
        "- We will use the same SLACK channel (https://join.slack.com/t/kaistcs576/shared_invite/zt-o3gqak0y-yj3NCb_SQFxVkqO0U6PWYw) as a main communication channel. When you post questions, please make it public so that all students can share the information. \n",
        "\n",
        "\n",
        "## Changelog\n",
        "- 04/18 03:02 : Added the cells defining result_dir and log_dir above the cell executing the tensorboard. Also added L12~L17 in the function train().\n",
        "- 04/18 14:01 : Removed remounting (the part including drive.mount('/content/drive'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3NY7sfLled4"
      },
      "source": [
        "---\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Prerequisite: change the runtime type to **GPU**.\n",
        "\n",
        "![test](https://docs.google.com/uc?export=download&id=1Jugrjl86L9EY1ePTjH8OVMFq7gmZsoz_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYfj23oOmOr6"
      },
      "source": [
        "---\n",
        "# Prerequisite: mount your gdrive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQdqM8z8ZM6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d1e22a-1fdd-47eb-c3d7-e81ad85537f0"
      },
      "source": [
        "# mount drive https://datascience.stackexchange.com/questions/29480/uploading-images-folder-from-my-system-into-google-colab\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W1NJ35eNLmt"
      },
      "source": [
        "---\n",
        "# Prerequisite: setup the `root` directory properly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlhMEGFUi-0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e6980cb-21b8-4e8a-cfce-4f3585b83215"
      },
      "source": [
        "# Specify the directory path where `assignemnt2.ipynb` and `dataset.tar.gz` exist.\n",
        "# For example, if you saved `assignment2.ipynb` and `dataset.tar.gz` in `/gdrive/My Drive/cs576/assignment2` directory,\n",
        "# then set root = '/gdrive/My Drive/cs576/assignment2'\n",
        "root = '/directory/path/where/assignment2.ipynb/exists'\n",
        "root = '/gdrive/My Drive/Colab Notebooks/Copy of assignment2'\n",
        "\n",
        "# Extract copied `dataset.tar.gz`.\n",
        "!tar -xzf '/gdrive/My Drive/'{root.replace('/gdrive/My Drive/', '').strip('/')}'/dataset.tar.gz'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tar (child): /gdrive/My Drive/Colab: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8ANEG5WmXzS"
      },
      "source": [
        "---\n",
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxNKZxIRYURA"
      },
      "source": [
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTx3YvqWYURE"
      },
      "source": [
        "-----\n",
        "\n",
        "# Network Modules\n",
        "\n",
        "In this section, you need to implement three modularized layer (or network) classes as follows:\n",
        "\n",
        "(1) plain residual block (ResBlockPlain)  \n",
        "(2) residual block with bottleneck (ResBlockBottleneck)  \n",
        "(3) an entire network module (MyNetwork)  \n",
        "\n",
        "\n",
        "In each cell, there is a starter code as well as a schematic illustration and instruction for implementing that module class. Specifically, the schematic illustrations are to show you the computational graphs of modules, which give you high-level views on how the modules should be constructed and work. (E.g. which nn.Module to use, or input/output shape of each layer written in italics). Therefore, please read the illustrations and instructions carefully to complete the codes.\n",
        "\n",
        "Below is an example.\n",
        "\n",
        "### Example: ConvLayer Module [(Illustration)](https://docs.google.com/drawings/d/1_aPhPSPgh5-5FEfI_jnfp8r6-wNjY_QYXBT3zzjkHk0/edit?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UCo9uoyYURE"
      },
      "source": [
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, activation_type='relu', use_bn=False):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        \"\"\"Initialize a basic convolutional layer module components.\n",
        "\n",
        "        Illustration: https://docs.google.com/drawings/d/1_aPhPSPgh5-5FEfI_jnfp8r6-wNjY_QYXBT3zzjkHk0/edit?usp=sharing\n",
        "\n",
        "        Instructions:\n",
        "            1. Implement an algorithm that initializes necessary components as illustrated in the above link. \n",
        "            2. Initialized network components will be referred in `forward` method \n",
        "               for constructing the dynamic computational graph.\n",
        "\n",
        "        Args:\n",
        "            1. in_channels (int): Number of channels in the input. \n",
        "            2. out_channels (int): Number of channels produced by the convolution.\n",
        "            3. activation_type (string, optional): Type of non-linear activation function to use. (default: 'relu') \n",
        "            4. use_bn (bool, optional): Whether to use batch normalization. (default: False)\n",
        "        \"\"\"\n",
        "        ##########################\n",
        "        ## Write your code here ##\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, 3, 1, 1)\n",
        "        self.bn = nn.BatchNorm2d(out_channels) if use_bn else nn.Identity() \n",
        "\n",
        "        if activation_type == 'relu':\n",
        "            self.act = nn.ReLU(True)\n",
        "        elif activation_type == 'lrelu':\n",
        "            self.act = nn.LeakyReLU(0.2, True)\n",
        "        elif activation_type == 'sigmoid':\n",
        "            self.act = nn.Sigmoid()\n",
        "        elif activation_type == 'tanh':\n",
        "            self.act = nn.Tanh()\n",
        "        elif activation_type == 'none':\n",
        "            self.act = nn.Identity() \n",
        "        else:\n",
        "            raise ValueError('Unknown activation_type !')\n",
        "        ##########################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Feed-forward the data `x` through the module.\n",
        "\n",
        "        Instructions:\n",
        "            1. Construct the feed-forward computational graph as illustrated in the link \n",
        "               using the initialized components in the __init__ method.\n",
        "\n",
        "        Args:\n",
        "            1. x (torch.FloatTensor): A tensor of shape (B, in_channels, H, W).\n",
        "\n",
        "        Returns:\n",
        "            1. output (torch.FloatTensor): An output tensor of shape (B, out_channels, H, W). \n",
        "\n",
        "        \"\"\"\n",
        "        ###########################\n",
        "        ## Write your code here ##\n",
        "        output = self.conv(x)\n",
        "        output = self.bn(output)\n",
        "        output = self.act(output)\n",
        "        ###########################\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBVoTVE2YURH"
      },
      "source": [
        "# Check and test your ConvLayer here\n",
        "# You may modify this cell for debugging\n",
        "\n",
        "in_channels = 8\n",
        "out_channels = 16\n",
        "activation_type = 'relu'\n",
        "use_bn = True\n",
        "\n",
        "convlayer_test = ConvLayer(in_channels, out_channels, activation_type, use_bn)\n",
        "print(convlayer_test)\n",
        "\n",
        "B, C, H, W = 1, in_channels, 32, 32\n",
        "x_test = torch.randn(1, C, H, W)\n",
        "print('input shape: ', x_test.shape, '| dtype: ', x_test.dtype)\n",
        "\n",
        "output = convlayer_test(x_test)\n",
        "print('output shape: ', output.shape, '| dtype: ', output.dtype)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-8Xz8c3YURK"
      },
      "source": [
        "### 1. Implement ResBlockPlain [(Illustration)](https://docs.google.com/drawings/d/1N0vi9S-RwDAjyJoC9eCVWwHnlKXfSlflf2xWTGEFRFQ/edit?usp=sharing) (10pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8UTAMTTYURL"
      },
      "source": [
        "class ResBlockPlain(nn.Module):\n",
        "    def __init__(self, in_channels, use_bn=False):\n",
        "        super(ResBlockPlain, self).__init__()\n",
        "        \"\"\"Initialize a residual block module components.\n",
        "\n",
        "        Illustration: https://docs.google.com/drawings/d/1N0vi9S-RwDAjyJoC9eCVWwHnlKXfSlflf2xWTGEFRFQ/edit?usp=sharing\n",
        "\n",
        "        Instructions:\n",
        "            1. Implement an algorithm that initializes necessary components as illustrated in the above link. \n",
        "            2. Initialized network components will be referred in `forward` method \n",
        "               for constructing the dynamic computational graph.\n",
        "\n",
        "        Args:\n",
        "            1. in_channels (int): Number of channels in the input.\n",
        "            2. use_bn (bool, optional): Whether to use batch normalization. (default: False)\n",
        "        \"\"\"\n",
        "        #################################\n",
        "        ## P1.1. Write your code here ##\n",
        "        #self.dummy_conv = nn.Conv2d(1, 1, 1, 1, 0) # Note: you must erase this line\n",
        "        self.conv=self.Conv2d(in)\n",
        "        #################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Feed-forward the data `x` through the network.\n",
        "\n",
        "        Instructions:\n",
        "            1. Construct the feed-forward computational graph as illustrated in the link \n",
        "               using the initialized components in __init__ method.\n",
        "\n",
        "        Args:\n",
        "            1. x (torch.FloatTensor): An tensor of shape (B, in_channels, H, W).\n",
        "\n",
        "        Returns:\n",
        "            1. output (torch.FloatTensor): An output tensor of shape (B, out_channels, H, W). \n",
        "        \"\"\"\n",
        "        ################################\n",
        "        ## P1.2. Write your code here ##\n",
        "        output = dummy_output = x # Note: you must erase this line\n",
        "        ################################\n",
        "        return output "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUTlFONeYURN"
      },
      "source": [
        "# Check and test your ResBlockPlain here\n",
        "# You may modify this cell for debugging\n",
        "\n",
        "in_channels = 16\n",
        "use_bn = True\n",
        "\n",
        "resblockplain_test = ResBlockPlain(in_channels, use_bn)\n",
        "print(resblockplain_test)\n",
        "\n",
        "B, C, H, W = 1, in_channels, 32, 32\n",
        "x_test = torch.randn(1, C, H, W)\n",
        "print('input shape: ', x_test.shape, '| dtype: ', x_test.dtype)\n",
        "\n",
        "output = resblockplain_test(x_test)\n",
        "print('output shape: ', output.shape, '| dtype: ', output.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkxVx30dYURQ"
      },
      "source": [
        "### 2. Implement ResBlockBottleneck [(Illustration)](https://docs.google.com/drawings/d/1cpqMoRKtVvLy6Zwt7HziEm3DyGsbNF6jYCTCCbm5WZY/edit?usp=sharing) (10pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0MZNQnoYURQ"
      },
      "source": [
        "class ResBlockBottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, use_bn=False):\n",
        "        super(ResBlockBottleneck, self).__init__()\n",
        "        \"\"\"Initialize a residual block module components.\n",
        "\n",
        "        Illustration: https://docs.google.com/drawings/d/1cpqMoRKtVvLy6Zwt7HziEm3DyGsbNF6jYCTCCbm5WZY/edit?usp=sharing\n",
        "\n",
        "        Instructions:\n",
        "            1. Implement an algorithm that initializes necessary components as illustrated in the above link. \n",
        "            2. Initialized network components will be referred in `forward` method \n",
        "               for constructing the dynamic computational graph.\n",
        "\n",
        "        Args:\n",
        "            1. in_channels (int): Number of channels in the input. \n",
        "            2. hidden_channels (int): Number of hidden channels produced by the first ConvLayer module.\n",
        "            3. use_bn (bool, optional): Whether to use batch normalization. (default: False)\n",
        "        \"\"\"\n",
        "        #################################\n",
        "        ## P2.1. Write your code here ##\n",
        "        self.dummy_conv = nn.Conv2d(1, 1, 1, 1, 0) # Note: you must erase this line\n",
        "        #################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Feed-forward the data `x` through the network.\n",
        "\n",
        "        Instructions:\n",
        "            1. Construct the feed-forward computational graph as illustrated in the link \n",
        "               using the initialized components in __init__ method.\n",
        "\n",
        "        Args:\n",
        "            1. x (torch.FloatTensor): An tensor of shape (B, in_channels, H, W).\n",
        "\n",
        "        Returns:\n",
        "            1. output (torch.FloatTensor): An output tensor of shape (B, out_channels, H, W). \n",
        "        \"\"\"\n",
        "        ################################\n",
        "        ## P2.2. Write your code here ##\n",
        "        output = dummy_output = x # Note: you must erase this line\n",
        "        ################################\n",
        "        return output "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Js1eoULYURT"
      },
      "source": [
        "# Check and test your ResBlockBottleneck here\n",
        "# You may modify this cell for debugging\n",
        "\n",
        "in_channels = 16\n",
        "hidden_channels = 8\n",
        "use_bn = True\n",
        "\n",
        "resblockbottleneck_test = ResBlockBottleneck(in_channels, hidden_channels, use_bn)\n",
        "print(resblockbottleneck_test)\n",
        "\n",
        "B, C, H, W = 1, in_channels, 32, 32\n",
        "x_test = torch.randn(1, C, H, W)\n",
        "print('input shape: ', x_test.shape, '| dtype: ', x_test.dtype)\n",
        "\n",
        "output = resblockbottleneck_test(x_test)\n",
        "print('output shape: ', output.shape, '| dtype: ', output.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXSb4yHIYURW"
      },
      "source": [
        "### 3. Implement MyNetwork [(Illustration)](https://docs.google.com/drawings/d/1dN2RLaCpK5W61A9s2WhdOfZDuDBn6JtIJmWmIAIMgtg/edit?usp=sharing) (20pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvdXrQUqYURW"
      },
      "source": [
        "class MyNetwork(nn.Module):\n",
        "    def __init__(self, nf, resblock_type='plain', num_resblocks=[1, 1, 1], use_bn=False):\n",
        "        super(MyNetwork, self).__init__()\n",
        "        \"\"\"Initialize an entire network module components.\n",
        "\n",
        "        Illustration: https://docs.google.com/drawings/d/1dN2RLaCpK5W61A9s2WhdOfZDuDBn6JtIJmWmIAIMgtg/edit?usp=sharing\n",
        "\n",
        "        Instructions:\n",
        "            1. Implement an algorithm that initializes necessary components as illustrated in the above link. \n",
        "            2. Initialized network components will be referred in `forward` method \n",
        "               for constructing the dynamic computational graph.\n",
        "\n",
        "        Args:\n",
        "            1. nf (int): Number of output channels for the first nn.Conv2d Module. An abbreviation for num_filter.\n",
        "            2. resblock_type (str, optional): Type of ResBlocks to use. ('plain' | 'bottleneck'. default: 'plain')\n",
        "            3. num_resblocks (list or tuple, optional): A list or tuple of length 3. \n",
        "               Each item at i-th index indicates the number of residual blocks at i-th Residual Layer.  \n",
        "               (default: [1, 1, 1])\n",
        "            4. use_bn (bool, optional): Whether to use batch normalization. (default: False)\n",
        "        \"\"\"\n",
        "        ################################\n",
        "        ## P3.1. Write your code here ##\n",
        "        self.dummy_conv = nn.Conv2d(1, 1, 1, 1, 0) # Note: you must erase this line\n",
        "        ################################\n",
        "\n",
        "        # When all components are initialized, perform weight initialization on weights and biases.\n",
        "        self.apply(self.init_params)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Feed-forward the data `x` through the network.\n",
        "\n",
        "        Instructions:\n",
        "            1. Construct the feed-forward computational graph as illustrated in the link \n",
        "               using the initialized network components in __init__ method.\n",
        "        Args:\n",
        "            1. x (torch.FloatTensor): An image tensor of shape (B, 3, 32, 32).\n",
        "\n",
        "        Returns:\n",
        "            1. output (torch.FloatTensor): An output tensor of shape (B, 10). \n",
        "        \"\"\"\n",
        "        ################################\n",
        "        ## P3.2. Write your code here ##\n",
        "        output = torch.tensor([[-0.1, 0.2, -0.3, 0.4, -0.5, 0.6, -0.7, 0.8, -0.9, 1.0]]).float() # Note: you must erase this line\n",
        "        ################################\n",
        "        return output\n",
        "\n",
        "    def init_params(self, m):\n",
        "        \"\"\"Perform weight initialization on model parameters.\n",
        "\n",
        "        Instructions:\n",
        "            1. For nn.Conv2d and nn.Linear modules, \n",
        "               initialize their weights using Kaiming He Normal initialization,\n",
        "               and initialize their biases with zeros.\n",
        "\n",
        "            2. For nn.BatchNorm2d modules,\n",
        "               initialize their weights with ones,\n",
        "               and initizlie their biases with zeros.\n",
        "\n",
        "            3. Otherwise, do not perform initialization.\n",
        "\n",
        "            4. No need to return anything in this method.\n",
        "\n",
        "            5. Hint: refer to the page 44 of the 'lecture note: tutorial on Pytorch [04/12]'\n",
        "\n",
        "        Args:\n",
        "            1. m (nn.Module) \n",
        "        \"\"\"\n",
        "        ################################\n",
        "        ## P3.3. Write your code here ##\n",
        "        ################################\n",
        "\n",
        "    def compute_loss(self, logit, y):\n",
        "        \"\"\"Compute cross entropy loss.\n",
        "\n",
        "        Hint: \n",
        "            If logit = torch.tensor([[-0.1, 0.2, -0.3, 0.4, -0.5, 0.6, -0.7, 0.8, -0.9, 1.0]]).float(),\n",
        "            and y = torch.ones(1).long(), then loss value equals to 2.3364xxxx\n",
        "\n",
        "        Args:\n",
        "            1. logit (torch.FloatTensor): A tensor of shape (B, 10). \n",
        "            2. y (torch.LongTensor): A tensor of shape (B).\n",
        "\n",
        "        Returns:\n",
        "            1. loss (torch.FloatTensor): Computed cross entropy loss.\n",
        "        \"\"\"\n",
        "        ################################\n",
        "        ## P3.4. Write your code here ##\n",
        "        loss = torch.tensor(2.3364) # Note: you must erase this line\n",
        "        ################################\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5pkWG-NYURY"
      },
      "source": [
        "# Check and test your Network here\n",
        "# You may modify this cell for debugging\n",
        "\n",
        "num_filters = 16\n",
        "num_resblocks = [1, 1, 1]\n",
        "resblock_type = 'bottleneck'\n",
        "use_bn = True\n",
        "\n",
        "mynetwork_test = MyNetwork(num_filters, resblock_type, num_resblocks, use_bn)\n",
        "print(mynetwork_test)\n",
        "\n",
        "B, C, H, W = 1, 3, 32, 32\n",
        "x_test = torch.randn(1, C, H, W)\n",
        "y_test = torch.ones(1).long()\n",
        "print('input shape: ', x_test.shape, '| dtype: ', x_test.dtype)\n",
        "print('label shape: ', y_test.shape, '| dtype: ', y_test.dtype)\n",
        "\n",
        "logit = mynetwork_test(x_test)\n",
        "print('logit shape: ', logit.shape, '| dtype: ', logit.dtype)\n",
        "\n",
        "loss_test = mynetwork_test.compute_loss(logit, y_test)\n",
        "print('computed loss:', loss_test.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlv0qsHZYURa"
      },
      "source": [
        "---\n",
        "\n",
        "# Dataset and DataLoader\n",
        "\n",
        "In this section, you need to implement data pipeline, as illustrated in **lecture note: Pytorch tutorial [4/12]**\n",
        "\n",
        "Like Network section, you are provided with starter codes for the data pipeline.\n",
        "\n",
        "Please refer to the instructions carefully to complete the codes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl4gTtF3aAZj"
      },
      "source": [
        "### 4-1. Implement CIFAR10 Dataset Class (15pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVl8_hECYURb"
      },
      "source": [
        "class CIFAR10(Dataset):\n",
        "    \"\"\"Customized `CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
        "\n",
        "    Read the following descriptions on the dataset directory structure carefully to implement this `CIFAR10` class.\n",
        "\n",
        "    In `dataset/cifar10` directory, you have `train` and `test` directories,\n",
        "    each of which contains CIFAR10 images for the train and test, respectively.\n",
        "\n",
        "    Also, there are 10 sub-directories (from `0` to `9`) in `train` and `test` directories, \n",
        "    where the name of each sub-directory is specified by CIFAR10 classes and \n",
        "    each sub-directory contains images for those classes. \n",
        "\n",
        "    For train data, there are 10*4,800=48,000 images in total (4,800 images for each class), \n",
        "    whereas test data consists of 10*1,200=12,000 images (1,200 images for each class). \n",
        "\n",
        "    For example,\n",
        "\n",
        "    datset\n",
        "        `-- cifar10\n",
        "            |-- train\n",
        "                |-- 0\n",
        "                    |-- 00001.png\n",
        "                    |-- ...\n",
        "                    `-- 04800.png\n",
        "                |-- ...\n",
        "                `-- 9\n",
        "                    |-- 00001.png\n",
        "                    |-- ...\n",
        "                    `-- 04800.png\n",
        "            `-- test\n",
        "                |-- 0\n",
        "                    |-- 04801.png\n",
        "                    |-- ...\n",
        "                    `-- 06000.png\n",
        "                |-- ...\n",
        "                `-- 9\n",
        "                    |-- 04801.png\n",
        "                    |-- ...\n",
        "                    `-- 06000.png\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, root, train=True, transform=None):\n",
        "        super(CIFAR10, self).__init__()\n",
        "        \"\"\"\n",
        "        Instructions: \n",
        "            1. Assume that `root` equals to `dataset/cifar10`.\n",
        "\n",
        "            2. If `train` is True, then parse all paths of train images, and keep them in the list `self.paths`. \n",
        "               E.g.) self.paths = ['dataset/cifar10/train/0/00001.png', ..., 'dataset/cifar10/train/9/4800.png']\n",
        "               Also, the length of `self.paths` list should be 48,000.\n",
        "                    \n",
        "            3. If `train` is False, then parse all paths of test images, and keep them in the list `self.paths`. \n",
        "               E.g.) self.paths = ['dataset/cifar10/test/0/04801.png', ..., 'dataset/cifar10/test/9/06000.png']\n",
        "               Also, the length of `self.paths` list should be 12,000.\n",
        "\n",
        "        Args:\n",
        "            root (string): Root directory of dataset where directory ``cifar10`` exists.\n",
        "            train (bool, optional): If True, creates dataset from training set, otherwise\n",
        "                creates from test set. (default: True)\n",
        "            transform (callable, optional): A function/transform that takes in an PIL image\n",
        "                and returns a transformed version. E.g, ``transforms.RandomCrop`` (default: None)\n",
        "        \"\"\"\n",
        "        self.transform = transform \n",
        "\n",
        "        ################################\n",
        "        ## P4.1. Write your code here ##\n",
        "        num_paths = 48000 if train is True else 12000                                 # Note: you must erase this line\n",
        "        dummy_paths = ['dataset/cifar10/train/0/00001.png' for _ in range(num_paths)] # Note: you must erase this line\n",
        "        self.paths = dummy_paths                                                      # Note: you must erase this line \n",
        "        ################################\n",
        "\n",
        "        assert isinstance(self.paths, (list,)), 'Wrong type. self.paths should be list.'\n",
        "        if train is True:\n",
        "            assert len(self.paths) == 48000, 'There are 48,000 train images, but you have gathered %d image paths' % len(self.paths)\n",
        "        else:\n",
        "            assert len(self.paths) == 12000, 'There are 12,000 test images, but you have gathered %d image paths' % len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Instructions:\n",
        "            1. Given a path of an image, which is grabbed by self.paths[idx], infer the class label of the image.\n",
        "            2. Convert the inferred class label into torch.LongTensor with shape (), and keep it in `label` variable.` \n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of self.paths\n",
        "\n",
        "        Returns:\n",
        "            image (torch.FloatTensor): An image tensor of shape (3, 32, 32).\n",
        "            label (torch.LongTensor): A label tensor of shape ().\n",
        "        \"\"\"\n",
        "\n",
        "        path = self.paths[idx] \n",
        "        # P4.2. Infer class label from `path`,\n",
        "        # write your code here.\n",
        "\n",
        "        # P4.3. Convert it to torch.LongTensor with shape ().\n",
        "        # label = write_your_code_here (one-liner).\n",
        "        label = torch.tensor(0) # Note: you must erase this line\n",
        "\n",
        "        image = Image.open(path)\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image) \n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZIE-uOHYURd"
      },
      "source": [
        "# Check and test your CIFAR10 Dataset class here.\n",
        "# You may modify this cell for debugging\n",
        "\n",
        "data_dir = 'dataset/cifar10'\n",
        "train = True\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "dset = CIFAR10(data_dir, train, transform)\n",
        "print('num data:', len(dset))\n",
        "\n",
        "x_test, y_test = dset[0]\n",
        "print('image shape:', x_test.shape, '| type:', x_test.dtype)\n",
        "print('label shape:', y_test.shape, '| type:', y_test.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-F_pYcbYURg"
      },
      "source": [
        "### 4-2. Implement DataLoader (5pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8ZmoESrYURg"
      },
      "source": [
        "def get_dataloader(args):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        ])\n",
        "    train_dataset = CIFAR10(args.dataroot, train=True, transform=transform)\n",
        "    test_dataset = CIFAR10(args.dataroot, train=False, transform=transform)\n",
        "\n",
        "    # P4.4. Use `DataLoader` module for mini-batching train and test datasets.\n",
        "    # train_dataloader = DataLoader(WRITE_YOUR_CODE_HERE, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
        "    # test_dataloader = DataLoader(WRITE_YOUR_CODE_HERE, batch_size=args.batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "    return train_dataloader, test_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_kBr92qYURi"
      },
      "source": [
        "---\n",
        "\n",
        "# 5. Train/Test Pipeline (40pt)\n",
        "\n",
        "In this section, you need to implement the entire train and test loop in the pipeline.\n",
        "\n",
        "Specifically, you need to do the followings:\n",
        "1. feed inputs into the network, get outputs, and then compute classification loss. \n",
        "2. backward the computed loss and update network weights (only in the training loop).\n",
        "3. save tensorboard logs frequently.\n",
        "4. save checkpoint weights frequently.\n",
        "\n",
        "Please refer to the **lecture note: Pytorch Tutorial [4/12]**. There are a lot of hints for implementing this pipeline !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vcdKxr7YURj"
      },
      "source": [
        "# Configurations & Hyper-parameters\n",
        "# You may modify this cell for your experiments. \n",
        "\n",
        "from easydict import EasyDict as edict\n",
        "\n",
        "args = edict()\n",
        "\n",
        "# basic options \n",
        "args.name = 'main'                   # experiment name.\n",
        "args.resume = False                  # whether to resume. If you want to resume training, change this option.\n",
        "args.ckpt_dir = 'ckpts'              # checkpoint directory name.\n",
        "args.ckpt_reload = '10'              # If you want to resume training, specify which epoch's checkpoint to re-load.\n",
        "args.gpu = True                      # whether or not to use gpu. \n",
        "\n",
        "# network options\n",
        "args.num_filters = 32                # number of output channels in the first nn.Conv2d module in MyNetwork.\n",
        "args.resblock_type = 'bottleneck'    # type of residual block. ('plain' | 'bottleneck').\n",
        "args.num_resblocks = [1, 2, 3]       # number of residual blocks in each Residual Layer.\n",
        "args.use_bn = False                  # whether or not to use batch normalization.\n",
        "\n",
        "# data options\n",
        "args.dataroot = 'dataset/cifar10'    # where CIFAR10 images exist.\n",
        "args.batch_size = 64                 # number of mini-batch size.\n",
        "\n",
        "# training options\n",
        "args.lr = 0.0001                     # learning rate.\n",
        "args.epoch = 50                      # training epoch.\n",
        "\n",
        "# tensorboard options\n",
        "args.tensorboard = True             # whether or not to use tensorboard logging.\n",
        "args.log_dir = 'logs'                # to which tensorboard logs will be saved.\n",
        "args.log_iter = 100                  # how frequently logs are saved."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cx7EgI__gse"
      },
      "source": [
        "# Added 04/18\n",
        "# Basic settings\n",
        "device = 'cuda' if torch.cuda.is_available() and args.gpu else 'cpu'\n",
        "\n",
        "result_dir = Path(root) / 'results' /args.name\n",
        "ckpt_dir = result_dir / args.ckpt_dir\n",
        "ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
        "log_dir = result_dir / args.log_dir\n",
        "log_dir.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0Ih-Yg0YURn"
      },
      "source": [
        "# Setup tensorboard.\n",
        "if args.tensorboard:\n",
        "    from torch.utils.tensorboard import SummaryWriter \n",
        "    writer = SummaryWriter(log_dir)\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir '/gdrive/My Drive/'{str(log_dir).replace('/gdrive/My Drive/', '')}\n",
        "else:\n",
        "    writer = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-ukFLINYURx"
      },
      "source": [
        "def train(args):\n",
        "\n",
        "    # Basic settings\n",
        "    device = 'cuda' if torch.cuda.is_available() and args.gpu else 'cpu'\n",
        "\n",
        "    result_dir = Path(root) / 'results' /args.name\n",
        "    ckpt_dir = result_dir / args.ckpt_dir\n",
        "    ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
        "    log_dir = result_dir / args.log_dir\n",
        "    log_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Added 04/18\n",
        "    if args.tensorboard:\n",
        "        from torch.utils.tensorboard import SummaryWriter \n",
        "        writer = SummaryWriter(log_dir)\n",
        "    else:\n",
        "        writer = None\n",
        "        \n",
        "    epoch = 0\n",
        "    global_step = 0\n",
        "    best_accuracy = 0.\n",
        "\n",
        "    # Define your model and optimizer\n",
        "    # Complete ResBlockPlain, ResBlockBottleneck, and MyNetwork modules to proceed further.\n",
        "    net = MyNetwork(args.num_filters, args.resblock_type, args.num_resblocks, args.use_bn).to(device)\n",
        "    optimizer = optim.Adam(net.parameters(), lr=args.lr)\n",
        "\n",
        "    # Resume the training \n",
        "    if args.resume:\n",
        "        ckpt_path = ckpt_dir / ('%s.pt' % args.ckpt_reload)\n",
        "\n",
        "        try:\n",
        "            checkpoint = torch.load(ckpt_path)\n",
        "            net.load_state_dict(checkpoint['net'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "            epoch = checkpoint['epoch'] + 1\n",
        "            best_accuracy = checkpoint['best_accuracy']\n",
        "            print(f'>> Resume training from epoch {epoch+1}')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "    # Get train/test data loaders  \n",
        "    # Complete CIFAR10 dataset class and get_dataloader method to proceed further.\n",
        "    train_dataloader, test_dataloader = get_dataloader(args)\n",
        "\n",
        "    # Start training\n",
        "    # Save the starting time\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epoch, args.epoch):\n",
        "        # start time\n",
        "        _start_time = time.time() \n",
        "\n",
        "        # Here starts the train loop.\n",
        "        net.train()\n",
        "        for x, y in train_dataloader:\n",
        "            global_step += 1\n",
        "\n",
        "            # P5.1. Send `x` and `y` to either cpu or gpu using `device` variable. \n",
        "            # x = write your code here (one-liner). \n",
        "            # y = write your code here (one-liner).\n",
        "            \n",
        "            # P5.2. Feed `x` into the network, get an output, and keep it in a variable called `logit`. \n",
        "            # logit = write your code here (one-liner).\n",
        "\n",
        "            # P5.3. Compute loss using `logit` and `y`, and keep it in a variable called `loss` \n",
        "            # loss =  write your code here (one-liner).\n",
        "            accuracy = (logit.argmax(dim=1)==y).float().mean()\n",
        "\n",
        "            # P5.4. flush out the previously computed gradient \n",
        "            # write your code here (one-liner).\n",
        "\n",
        "            # P5.5. backward the computed loss. \n",
        "            # write your code here (one-liner).\n",
        "\n",
        "            # P5.6. update the network weights. \n",
        "            # write your code here (one-liner).\n",
        "\n",
        "            if global_step % args.log_iter == 0 and writer is not None:\n",
        "                # P5.7. Log `loss` with a tag name 'train_loss' using `writer`. Use `global_step` as a timestamp for the log. \n",
        "                # writer.writer_your_code_here (one-liner).\n",
        "                # P5.8. Log `accuracy` with a tag name 'train_accuracy' using `writer`. Use `global_step` as a timestamp for the log. \n",
        "                # writer.writer_your_code_here (one-liner).\n",
        "\n",
        "        # print train loss, acc, time spent \n",
        "        t = time.time()-_start_time\n",
        "        print(f'Epoch {epoch}/{args.epoch} || train loss={loss:.4f} train acc={accuracy*100:.3f}% time={t:.3f} secs')\n",
        "\n",
        "        # start time for test\n",
        "        _start_time = time.time() \n",
        "\n",
        "        # Here starts the test loop.\n",
        "        net.eval()\n",
        "        with torch.no_grad():\n",
        "            test_loss = 0.\n",
        "            test_accuracy = 0.\n",
        "            test_num_data = 0.\n",
        "            for x, y in test_dataloader:\n",
        "                # P5.9. Send `x` and `y` to either cpu or gpu using `device` variable.\n",
        "                # x = write your code here (one-liner).\n",
        "                # y = write your code here (one-liner).\n",
        "\n",
        "                # P5.10. Feed `x` into the network, get an output, and keep it in a variable called `logit`.\n",
        "                # logit = write your code here (one-liner). \n",
        "\n",
        "                # P5.11. Compute loss using `logit` and `y`, and keep it in a variable called `loss`\n",
        "                # loss = write your code yere (one-liner). \n",
        "                accuracy = (logit.argmax(dim=1) == y).float().mean()\n",
        "\n",
        "                test_loss += loss.item()*x.shape[0]\n",
        "                test_accuracy += accuracy.item()*x.shape[0]\n",
        "                test_num_data += x.shape[0]\n",
        "\n",
        "            test_loss /= test_num_data\n",
        "            test_accuracy /= test_num_data\n",
        "\n",
        "            if writer is not None: \n",
        "                # P5.12. Log `test_loss` with a tag name 'test_loss' using `writer`. Use `global_step` as a timestamp for the log.\n",
        "                # writer.write_your_code_here (one-liner).\n",
        "                # P5.13. Log `test_accuracy` with a tag name 'test_accuracy' using `writer`. Use `global_step` as a timestamp for the log.\n",
        "                # writer.write_your_code_here (one-liner).\n",
        "                writer.flush()\n",
        "\n",
        "            # P5.14. Whenever `test_accuracy` is greater than `best_accuracy`, save network weights with the filename 'best.pt' in the directory specified by `ckpt_dir`.\n",
        "            #     Here, just save the network weights (i.e, you don't need to save optimizer)\n",
        "            #     Also, don't forget to update the `best_accuracy` properly.\n",
        "            # write your code here. \n",
        "\n",
        "        # P5.15. Save the checkpoint in the directory specified by `ckpt_dir` directory. \n",
        "        #    Note that the checkpoint must include network weights, optmizer states, current epoch, best acuuracy so far. \n",
        "        #    To see how those parameters are loaded, see the above cell that loads the checkpoint and resumes the training. \n",
        "        #    Hint) Write something like, torch.save(dict(epoch=, net=, optimizer=, best_accuracy=), checkpoint_filename)\n",
        "        #    Also, use `epoch` to specify the timestamp in the checkpoint filename.\n",
        "        #    E.g) if `epoch=10`, the filename can be `10.pt`\n",
        "        # write your code here (one-liner).\n",
        "\n",
        "        # print test loss, acc, time spent\n",
        "        t = time.time()-_start_time\n",
        "        print(f'Epoch {epoch}/{args.epoch} || test loss={loss:.4f} test acc={test_accuracy*100:.3f}% time={t:.3f} secs')\n",
        "\n",
        "    # Print final accuracy with total time spent for training\n",
        "    total_t = time.time()-start_time \n",
        "    print(f'Final best accuracy : {best_accuracy*100:.3f}% total time={total_t:.3f} secs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVcX2qpAQin9"
      },
      "source": [
        "# Training\n",
        "train(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z1APMygJ8Um"
      },
      "source": [
        "---\n",
        "# 6. Discussions (50pt)\n",
        "\n",
        "Train and test at least 3 models with different configurations (for example, test with `ResBlockPlain` block instead of `ResBlockBottleneck` or you may stack more layers, etc) and hyper-parameters and discuss the results. Simply reporting the results (e.g. classification accuracy) is not considered as a discussion. You should explain which components lead to differences and analyze the reason for those differences. \n",
        "\n",
        "For the experiments, you can change the configurations and hyper-parameters by modifying the values written in the cell defining configurations and hyper-parameters. **Also, don't forget to change `args.name` before you run the new experiment!** \n",
        "\n",
        "Then, run the experiments below and leave the logs including test accuracy as a proof that you actually conducted the experiments. Based on the experimental results, write your discussions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR71pz1sSl5l"
      },
      "source": [
        "* Experiment #1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKgckqCaSmLZ"
      },
      "source": [
        "# Run your Experiment here\n",
        "# You may add cells if you want"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GhEgRmOSmWP"
      },
      "source": [
        "* Experiment #2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaP--GX2SmdG"
      },
      "source": [
        "# Run your Experiment here\n",
        "# You may add cells if you want"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW1IFBbYSmki"
      },
      "source": [
        "* Experiment #3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWab_SYcSmqi"
      },
      "source": [
        "# Run your Experiment here\n",
        "# You may add cells if you want"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-uLNbb1S2RI"
      },
      "source": [
        "* Your discussions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdmbjJ3xSvx7"
      },
      "source": [
        "Write disccusions here..."
      ]
    }
  ]
}